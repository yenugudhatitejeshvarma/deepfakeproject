# ğŸ¯ Deepfake Detector Project - Complete Overview

## ğŸ“‚ Project Files Structure

```
deepfakeproject/
â”‚
â”œâ”€â”€ ğŸ Python Scripts (Core)
â”‚   â”œâ”€â”€ download_model.py      # Download model from Hugging Face
â”‚   â”œâ”€â”€ run_model.py           # â­ MAIN: Run inference on images
â”‚   â”œâ”€â”€ test_model.py          # Quick model verification
â”‚   â”œâ”€â”€ verify_model.py        # Detailed model verification
â”‚   â””â”€â”€ check_gpu.py           # Check GPU availability
â”‚
â”œâ”€â”€ ğŸš€ Wrapper Scripts (Easy Execution)
â”‚   â”œâ”€â”€ run_model.bat          # Windows batch file
â”‚   â””â”€â”€ run_model.ps1          # PowerShell script
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ FILES_EXPLANATION.md   # Detailed file explanations
â”‚   â”œâ”€â”€ EXECUTION_SUMMARY.md   # How the model ran
â”‚   â””â”€â”€ PROJECT_OVERVIEW.md    # This file
â”‚
â””â”€â”€ ğŸ–¼ï¸ Test Images
    â””â”€â”€ 1.png                  # Your test image
```

---

## ğŸ¬ Execution Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    USER RUNS COMMAND                        â”‚
â”‚              python run_model.py 1.png                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [1] GPU CHECK                                              â”‚
â”‚  â€¢ Check CUDA availability                                  â”‚
â”‚  â€¢ Select device (GPU/CPU)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [2] MODEL CACHE LOCATION                                   â”‚
â”‚  â€¢ Check: C:\Users\...\.cache\huggingface\hub\             â”‚
â”‚  â€¢ Path: models--prithivMLmods--deepfake-detector-model-v1  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [3] LOAD MODEL                                             â”‚
â”‚  â€¢ Load from Hugging Face cache                             â”‚
â”‚  â€¢ Model: SiglipForImageClassification                      â”‚
â”‚  â€¢ Parameters: 92,885,762                                   â”‚
â”‚  â€¢ Time: ~11.67 seconds (first time)                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [4] MOVE TO DEVICE                                         â”‚
â”‚  â€¢ Move model to GPU (if available) or CPU                  â”‚
â”‚  â€¢ Time: <0.01 seconds                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [5] LOAD IMAGE                                             â”‚
â”‚  â€¢ Open: 1.png                                              â”‚
â”‚  â€¢ Convert to RGB                                           â”‚
â”‚  â€¢ Time: ~0.016 seconds                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [6] PREPROCESS IMAGE                                       â”‚
â”‚  â€¢ Resize to 224x224                                        â”‚
â”‚  â€¢ Normalize pixel values                                   â”‚
â”‚  â€¢ Move to device (GPU/CPU)                                 â”‚
â”‚  â€¢ Time: ~0.003 seconds                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [7] RUN INFERENCE                                          â”‚
â”‚  â€¢ Forward pass through model                               â”‚
â”‚  â€¢ Get logits                                               â”‚
â”‚  â€¢ Apply softmax                                            â”‚
â”‚  â€¢ Time: ~0.29 seconds (CPU) / ~0.03 seconds (GPU)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  [8] DISPLAY RESULTS                                        â”‚
â”‚  â€¢ Predicted: REAL/FAKE                                     â”‚
â”‚  â€¢ Confidence: 50.36%                                       â”‚
â”‚  â€¢ Probabilities for both classes                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Model Storage Location

### âŒ NOT in Project Directory
The model is **NOT** stored in `T:\deepfakeproject\`

### âœ… Actual Location
```
C:\Users\TWLESH VARMA\.cache\huggingface\hub\
â””â”€â”€ models--prithivMLmods--deepfake-detector-model-v1/
    â””â”€â”€ snapshots/
        â””â”€â”€ [commit_hash]/
            â”œâ”€â”€ config.json              # Model configuration
            â”œâ”€â”€ model.safetensors        # Model weights (92.8M params)
            â””â”€â”€ preprocessor_config.json # Image processor config
```

**Why?**
- Standard Hugging Face cache location
- Shared across all projects
- Automatically managed
- Saves disk space

---

## ğŸ“Š Files Used During Execution

### When you run: `python run_model.py 1.png`

#### **Python Scripts:**
1. âœ… `run_model.py` - Main script (executed)
2. âœ… `transformers` library - Model framework
3. âœ… `torch` (PyTorch) - Deep learning backend
4. âœ… `PIL` (Pillow) - Image processing

#### **Model Files (from cache):**
1. âœ… `config.json` - Model architecture
2. âœ… `model.safetensors` - Model weights
3. âœ… `preprocessor_config.json` - Image processor

#### **Input:**
1. âœ… `1.png` - Your image file

---

## ğŸ¯ File Purpose Summary

| File | Purpose | When Used |
|------|---------|-----------|
| **download_model.py** | Download model from Hugging Face | Once initially |
| **run_model.py** â­ | Run inference on images | Every time |
| **test_model.py** | Quick model test | After download |
| **verify_model.py** | Verify real model | To confirm |
| **check_gpu.py** | Check GPU availability | To verify GPU |
| **run_model.bat** | Windows wrapper | Easy execution |
| **run_model.ps1** | PowerShell wrapper | Easy execution |

---

## âš¡ GPU Support

### Current Status:
- âŒ **No GPU detected** - Running on CPU
- âœ… **Code is GPU-ready** - Will auto-use GPU if available

### GPU Detection:
The code automatically:
1. Checks for CUDA availability
2. Uses GPU if available
3. Falls back to CPU if no GPU

### Expected Performance:
- **CPU:** ~0.29 seconds per image
- **GPU:** ~0.03 seconds per image (10x faster!)

---

## ğŸ“ˆ Performance Metrics

### Last Run Statistics:
```
Total Time: 11.99 seconds
â”œâ”€â”€ Model Loading: 11.67s (97.3%)
â”œâ”€â”€ Image Loading: 0.016s (0.1%)
â”œâ”€â”€ Preprocessing: 0.003s (0.03%)
â””â”€â”€ Inference: 0.292s (2.4%)
```

### Next Run (Model Already Loaded):
```
Total Time: ~0.3 seconds
â”œâ”€â”€ Image Loading: 0.016s
â”œâ”€â”€ Preprocessing: 0.003s
â””â”€â”€ Inference: 0.292s
```

---

## ğŸ”‘ Key Points

1. âœ… **Real Model** - 92.8M parameters from Hugging Face
2. âœ… **GPU-Ready** - Automatically uses GPU if available
3. âœ… **Cached Model** - Stored in Hugging Face cache (not project folder)
4. âœ… **Fast Inference** - 0.29s per image on CPU
5. âœ… **Detailed Logging** - Shows every step
6. âœ… **Easy to Use** - Simple command-line interface

---

## ğŸš€ Quick Start

### First Time:
```bash
python download_model.py  # Download model (once)
python run_model.py 1.png  # Run inference
```

### Subsequent Runs:
```bash
python run_model.py 1.png  # Just run inference
```

### Using Wrappers:
```bash
.\run_model.ps1 1.png  # PowerShell
run_model.bat 1.png    # Batch file
```

---

## ğŸ“š Documentation Files

- **FILES_EXPLANATION.md** - Detailed explanation of each file
- **EXECUTION_SUMMARY.md** - How the model ran with timings
- **PROJECT_OVERVIEW.md** - This overview document

